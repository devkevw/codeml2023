{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bbb395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages and modules\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9289f7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dx/66dwwfp55d1032n4tz8r0mz00000gp/T/ipykernel_30276/1930653572.py:2: DtypeWarning: Columns (1270,1271,1272) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data_participant_ECCC.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>start_time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>event</th>\n",
       "      <th>r_300.t-6</th>\n",
       "      <th>...</th>\n",
       "      <th>LD.t-2</th>\n",
       "      <th>LD.t-1</th>\n",
       "      <th>LD.t+0</th>\n",
       "      <th>LD.t+1</th>\n",
       "      <th>LD.t+2</th>\n",
       "      <th>LD.t+3</th>\n",
       "      <th>hail_size</th>\n",
       "      <th>y_thunderstorm</th>\n",
       "      <th>y_hail</th>\n",
       "      <th>y_severe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4/8/2005 4:00</td>\n",
       "      <td>56.129</td>\n",
       "      <td>-119.081980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.769104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4/8/2005 8:00</td>\n",
       "      <td>52.129</td>\n",
       "      <td>-119.081980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.736720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4/13/2005 2:00</td>\n",
       "      <td>48.379</td>\n",
       "      <td>-114.331790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.332287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>4/21/2005 2:00</td>\n",
       "      <td>53.879</td>\n",
       "      <td>-105.831436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.939270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2005</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>5/3/2005 21:00</td>\n",
       "      <td>52.879</td>\n",
       "      <td>-115.831850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.186860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.004847</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1273 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  year  month  day  hour      start_time  latitude   longitude  event  \\\n",
       "0   0  2005      4    8     4   4/8/2005 4:00    56.129 -119.081980    NaN   \n",
       "1   1  2005      4    8     8   4/8/2005 8:00    52.129 -119.081980    NaN   \n",
       "2   2  2005      4   13     2  4/13/2005 2:00    48.379 -114.331790    NaN   \n",
       "3   3  2005      4   21     2  4/21/2005 2:00    53.879 -105.831436    NaN   \n",
       "4   4  2005      5    3    21  5/3/2005 21:00    52.879 -115.831850    NaN   \n",
       "\n",
       "    r_300.t-6  ...    LD.t-2    LD.t-1    LD.t+0    LD.t+1    LD.t+2  \\\n",
       "0   98.769104  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  100.736720  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2   33.332287  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3   83.939270  ...  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4   95.186860  ...  0.000048  0.000451  0.001993  0.004847  0.000247   \n",
       "\n",
       "     LD.t+3  hail_size  y_thunderstorm  y_hail  y_severe  \n",
       "0  0.000000        0.0           False   False     False  \n",
       "1  0.000000        0.0           False   False     False  \n",
       "2  0.000000        0.0           False   False     False  \n",
       "3  0.000000        0.0           False   False     False  \n",
       "4  0.001017        0.0            True   False     False  \n",
       "\n",
       "[5 rows x 1273 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gather data\n",
    "df = pd.read_csv('data_participant_ECCC.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d97cddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into two (one with missing y values and one without)\n",
    "missing_y = df['y_thunderstorm'].isna() & df['y_hail'].isna() & df['y_severe'].isna()\n",
    "df_predict = df[missing_y]\n",
    "df_remaining = df[~missing_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf36c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df_remaining into data frames that are/are not missing hail_size values\n",
    "missing_hail_size = df_remaining['hail_size'].isna()\n",
    "df_wo_hail_size = df_remaining[missing_hail_size]\n",
    "df_cleaned = df_remaining[~missing_hail_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a21068a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in cleaned data: 0\n",
      "y_thunderstorm\n",
      "True     5783\n",
      "False    3249\n",
      "Name: count, dtype: int64\n",
      "y_hail\n",
      "True     5516\n",
      "False    3516\n",
      "Name: count, dtype: int64\n",
      "y_severe\n",
      "False    5506\n",
      "True     3526\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Isolate outputs with values\n",
    "y1 = df_cleaned['y_thunderstorm']\n",
    "y2 = df_cleaned['y_hail']\n",
    "y3 = df_cleaned['y_severe']\n",
    "\n",
    "print(f'Duplicates in cleaned data: {df_cleaned.duplicated().sum()}')\n",
    "print(y1.value_counts())\n",
    "print(y2.value_counts())\n",
    "print(y3.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9279e82a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for y_thunderstorm: 95.07%\n",
      "Accuracy for y_hail: 94.80%\n",
      "Accuracy for y_severe: 95.02%\n",
      "Overall accuracy: 94.96%\n"
     ]
    }
   ],
   "source": [
    "# Train models for y_thunderstorm, y_hail, y_severe\n",
    "model1 = DecisionTreeClassifier()\n",
    "X_train, X_test, y1_train, y1_test = train_test_split(df_cleaned.drop(columns=['ID', 'year', 'month', 'day', 'hour', 'start_time', 'latitude', 'longitude', 'event', 'y_thunderstorm', 'y_hail', 'y_severe']), y1.astype(int), test_size=0.2, random_state=42)\n",
    "model1.fit(X_train, y1_train)\n",
    "\n",
    "predictions1 = model1.predict(X_test)\n",
    "score1 = accuracy_score(y1_test, predictions1)\n",
    "\n",
    "model2 = DecisionTreeClassifier()\n",
    "X_train, X_test, y2_train, y2_test = train_test_split(df_cleaned.drop(columns=['ID', 'year', 'month', 'day', 'hour', 'start_time', 'latitude', 'longitude', 'event', 'y_thunderstorm', 'y_hail', 'y_severe']), y2.astype(int), test_size=0.2)\n",
    "model2.fit(X_train, y2_train)\n",
    "\n",
    "predictions2 = model2.predict(X_test)\n",
    "score2 = accuracy_score(y2_test, predictions2)\n",
    "\n",
    "model3 = DecisionTreeClassifier()\n",
    "X_train, X_test, y3_train, y3_test = train_test_split(df_cleaned.drop(columns=['ID', 'year', 'month', 'day', 'hour', 'start_time', 'latitude', 'longitude', 'event', 'y_thunderstorm', 'y_hail', 'y_severe']), y3.astype(int), test_size=0.2)\n",
    "model3.fit(X_train, y3_train)\n",
    "\n",
    "predictions3 = model3.predict(X_test)\n",
    "score3 = accuracy_score(y3_test, predictions3)\n",
    "\n",
    "print(f\"Accuracy for y_thunderstorm: {score1*100:.2f}%\")\n",
    "print(f\"Accuracy for y_hail: {score2*100:.2f}%\")\n",
    "print(f\"Accuracy for y_severe: {score3*100:.2f}%\")\n",
    "print(f\"Overall accuracy: {(score1 + score2 + score3)/3*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50e09df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict missing values of y_thunderstorm, y_hail, y_severe\n",
    "y1_predict = model1.predict(df_predict.drop(columns=['ID', 'year', 'month', 'day', 'hour', 'start_time', 'latitude', 'longitude', 'event', 'y_thunderstorm', 'y_hail', 'y_severe'])).astype(bool)\n",
    "y2_predict = model2.predict(df_predict.drop(columns=['ID', 'year', 'month', 'day', 'hour', 'start_time', 'latitude', 'longitude', 'event', 'y_thunderstorm', 'y_hail', 'y_severe'])).astype(bool)\n",
    "y3_predict = model3.predict(df_predict.drop(columns=['ID', 'year', 'month', 'day', 'hour', 'start_time', 'latitude', 'longitude', 'event', 'y_thunderstorm', 'y_hail', 'y_severe'])).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "941ba6ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replace missing y-values with predictions\n",
    "df_predict_new = df_predict.drop(columns=['y_thunderstorm', 'y_hail', 'y_severe'])\n",
    "df_predict_new['y_thunderstorm'] = y1_predict\n",
    "df_predict_new['y_hail'] = y2_predict\n",
    "df_predict_new['y_severe'] = y3_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d354ae5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Combine all sub data frames into complete final data frame\n",
    "df_final = pd.concat([df_predict_new, df_wo_hail_size, df_cleaned], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4914c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save .csv file, to be submitted for evaluation\n",
    "df_final.to_csv('output_ECCC.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
